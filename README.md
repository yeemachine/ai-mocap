# AI Motion Capture for Designers
![Drawing of a person controlling an avatar with motion capture](https://github.com/yeemachine/ai-mocap/blob/main/ai-mocap-landscape.gif?raw=true)
- Instructor: Rich Yee
- Email: rich@yeemachine.com
- Office hours: Message on Slack

## Course Description:
This course introduces the basics of MediaPipe and Tensorflow.js, two powerful frameworks for building machine learning pipelines for processing video and images. You will learn how to create real-time video effects using face, hand, and pose detection. You will also learn how to use web technologies like WebGL to run and render your effects in the browser. Although this course will be taught using web technologies, you are welcome to explore other languages since the frameworks we will be covering are cross-platform. By the end of this course, you will be able to create your own experiences that leverage MediaPipe and other tools for your design projects.

## Prerequisites:
- Basic web development knowledge (HTML, CSS, JavaScript)
- Node.js and NPM knowledge preferred
- Familiarity with Machine Learning + AI (optional)

## Course Objectives:
- Understand the principles and components of motion capture
- Set up face, hands, and pose tracking solutions from MediaPipe/Tensorflow.js 
- Apply video effects using your preferred graphics frameworks
- Design and implement a web-based video effect project

## Required Resources:
- A computer with a webcam and a microphone
- A web browser that supports WebGL (Chrome, Firefox, Safari, etc.)
- A code editor (VS Code, Sublime Text, etc.)
- A GitHub account or Glitch account

## Course Outline:

| Week | Topic | Activity | Assignment |
|------|-------|----------|------------|
| 1 | Introduction to Motion Capture on the web | Lecture: What is MediaPipe/Tensorflow.js and why use it? <br> Demo: Hello World with MediaPipe <br> Lab: Set up your development environment + Intro to useful graphics frameworks | Assignment 0: Think of 3 potential mocap project ideas and start setting up your own dev environment |
| 2 | Face Landmarks and Attention Mesh | Lecture: How does face detection and mesh work? <br> Demo: Face landmarks and contours <br> Lab: Apply face effects using WebGL | Assignment 1: Create a face filter |
| 3 | Hand Tracking | Lecture: How does hand detection and tracking work? <br> Demo: Hand landmarks and gestures <br> Lab: Apply hand effects using WebGL | Assignment 2: Create an AR hand effect |
| 4 | Pose Detection and Body Segmentation | Lecture: How does pose detection and tracking work? <br> Demo: Pose landmarks and segmentation <br> Lab: Apply pose effects using WebGL | Assignment 3: Create an app that uses the whole body |
| 5 | Final Critique and Advanced Workflows | Presentations: Demo Day! Present your final projects to the class. We'll discuss and critique as a group. | Keep co-creating with AI! |



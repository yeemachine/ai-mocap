# Course Syllabus: Co-Creating with AI: Motion Capture for Designers

## Instructor: 
- Name: 
- Email: 
- Office hours:

## Course Description:
This course introduces the basics of MediaPipe and Tensorflow.js, two powerful frameworks for building machine learning pipelines for processing video and images. You will learn how to create real-time video effects using face, hand, and pose detection. You will also learn how to use web technologies like WebGL to run and render your effects in the browser. Although this course will be taught using web technologies, you are welcome to explore other languages since the frameworks we will be covering are cross-platform. By the end of this course, you will be able to create your own experiences that leverage MediaPipe and other tools for your design projects.

## Prerequisites:
- Basic web development knowledge (HTML, CSS, JavaScript)
- Familiarity with machine learning concepts (optional)

## Course Objectives:
- Understand the principles and components of MediaPipe
- Use MediaPipe Face Mesh, Hand Tracking, and Pose Tracking solutions
- Apply video effects using WebGL frameworks like Three.js, Pixi.js, P5.js etc
- Integrate MediaPipe with TensorFlow.js and WebGL
- Design and implement a web-based video effect project

## Required Resources:
- A computer with a webcam and a microphone
- A web browser that supports WebGL (Chrome, Firefox, Safari, etc.)
- A code editor (VS Code, Sublime Text, etc.)
- A GitHub account

## Course Outline:

| Week | Topic | Activity | Assignment |
|------|-------|----------|------------|
| 1 | Introduction to MediaPipe | Lecture: What is MediaPipe and why use it? <br> Demo: Hello World with MediaPipe <br> Lab: Set up your development environment | Assignment 0: Think of 3 potential mocap project ideas and finish setting up your own dev environment |
| 2 | Face Detection and Mesh | Lecture: How does face detection and mesh work? <br> Demo: Face landmarks and contours <br> Lab: Apply face effects using OpenGL ES | Assignment 1: Create a face filter |
| 3 | Hand Detection and Tracking | Lecture: How does hand detection and tracking work? <br> Demo: Hand landmarks and gestures <br> Lab: Apply hand effects using OpenGL ES | Assignment 2: Create an AR hand effect |
| 4 | Pose Detection and Tracking | Lecture: How does pose detection and tracking work? <br> Demo: Pose landmarks and segmentation <br> Lab: Apply pose effects using OpenGL ES | Assignment 2: Create an app that involves the whole body |
| 5 | Web Integration and Deployment | Lecture: How to use TensorFlow.js and WebGL with MediaPipe <br> Demo: Run and render MediaPipe in the browser <br> Lab: Design and implement your final project | Final Project: Create a web-based video effect experience |
| 6 | Final Critique and Sharing | Lecture: How to use TensorFlow.js and WebGL with MediaPipe <br> Demo: Run and render MediaPipe in the browser <br> Lab: Design and implement your final project | Have fun co-creating with AI! |


